# Endpoint padrao do Ollama
#langchain4j.ollama.chat-model.base-url=http://localhost:11434

# Nome exato do modelo (deve ser o mesmo que aparece em 'ollama list')
#langchain4j.ollama.chat-model.model-name=deepseek-r1:8b

# Configura�oes de par�metros (opcional)
#langchain4j.ollama.chat-model.temperature=0.7
#langchain4j.ollama.chat-model.top-p=1.0

# IMPORTANTE: Aumentar o timeout para modelos grandes (20b+)
# O valor est� em milissegundos (ex: 60 segundos)
#langchain4j.ollama.chat-model.timeout=PT60S

#langchain4j.google-ai.model-name=gemini-1.5-flash
# O modelo 'flash' � extremamente r�pido e ideal para testes.
# Use 'gemini-1.5-pro' para tarefas mais complexas.

server.port=8081

# PostgreSQL Configuration
spring.datasource.url=jdbc:postgresql://localhost:5432/ai_agent_db
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true